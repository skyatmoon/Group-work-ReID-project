{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from os import path as osp\n",
    "import glob\n",
    "import re\n",
    "import scipy.io as sio\n",
    "from mxnet import autograd, gluon, image, init, nd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from mxnet.gluon.data import DataLoader\n",
    "from mxnet.gluon.data import Dataset\n",
    "from mxnet.image import imread\n",
    "from mxnet.gluon import nn,model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Market1501(object):\n",
    "\n",
    "    dataset_dir = 'Market-1501-v15.09.15'\n",
    "\n",
    "    def __init__(self, root='', **kwargs):\n",
    "        self.dataset_dir = osp.join(root, self.dataset_dir)\n",
    "        self.train_dir = osp.join(self.dataset_dir, 'bounding_box_train')\n",
    "        self.query_dir = osp.join(self.dataset_dir, 'query')\n",
    "        self.gallery_dir = osp.join(self.dataset_dir, 'bounding_box_test')\n",
    "\n",
    "        self._check_before_run()\n",
    "\n",
    "        train, num_train_pids, num_train_imgs = self._process_dir(self.train_dir, relabel=True)\n",
    "        query, num_query_pids, num_query_imgs = self._process_dir(self.query_dir, relabel=False)\n",
    "        gallery, num_gallery_pids, num_gallery_imgs = self._process_dir(self.gallery_dir, relabel=False)\n",
    "        num_total_pids = num_train_pids + num_query_pids\n",
    "        num_total_imgs = num_train_imgs + num_query_imgs + num_gallery_imgs\n",
    "\n",
    "        print(\"=> Market1501 loaded\")\n",
    "        print(\"Dataset statistics:\")\n",
    "        print(\"  ------------------------------\")\n",
    "        print(\"  subset   | # ids | # images\")\n",
    "        print(\"  ------------------------------\")\n",
    "        print(\"  train    | {:5d} | {:8d}\".format(num_train_pids, num_train_imgs))\n",
    "        print(\"  query    | {:5d} | {:8d}\".format(num_query_pids, num_query_imgs))\n",
    "        print(\"  gallery  | {:5d} | {:8d}\".format(num_gallery_pids, num_gallery_imgs))\n",
    "        print(\"  ------------------------------\")\n",
    "        print(\"  total    | {:5d} | {:8d}\".format(num_total_pids, num_total_imgs))\n",
    "        print(\"  ------------------------------\")\n",
    "\n",
    "        self.train = train\n",
    "        self.query = query\n",
    "        self.gallery = gallery\n",
    "\n",
    "        self.num_train_pids = num_train_pids\n",
    "        self.num_query_pids = num_query_pids\n",
    "        self.num_gallery_pids = num_gallery_pids\n",
    "\n",
    "    def _check_before_run(self):\n",
    "        \"\"\"Check if all files are available before going deeper\"\"\"\n",
    "        if not osp.exists(self.dataset_dir):\n",
    "            raise RuntimeError(\"'{}' is not available\".format(self.dataset_dir))\n",
    "        if not osp.exists(self.train_dir):\n",
    "            raise RuntimeError(\"'{}' is not available\".format(self.train_dir))\n",
    "        if not osp.exists(self.query_dir):\n",
    "            raise RuntimeError(\"'{}' is not available\".format(self.query_dir))\n",
    "        if not osp.exists(self.gallery_dir):\n",
    "            raise RuntimeError(\"'{}' is not available\".format(self.gallery_dir))\n",
    "\n",
    "    def _process_dir(self, dir_path, relabel=False):\n",
    "        img_paths = glob.glob(osp.join(dir_path, '*.jpg'))\n",
    "        pattern = re.compile(r'([-\\d]+)_c(\\d)')\n",
    "\n",
    "        pid_container = set()\n",
    "        for img_path in img_paths:\n",
    "            pid, _ = map(int, pattern.search(img_path).groups())\n",
    "            if pid == -1: continue  # junk images are just ignored\n",
    "            pid_container.add(pid)\n",
    "        pid2label = {pid: label for label, pid in enumerate(pid_container)}\n",
    "\n",
    "        dataset = []\n",
    "        for img_path in img_paths:\n",
    "            pid, camid = map(int, pattern.search(img_path).groups())\n",
    "            if pid == -1:\n",
    "                continue  # junk images are just ignored\n",
    "            assert 0 <= pid <= 1501  # pid == 0 means background\n",
    "            assert 1 <= camid <= 6\n",
    "            camid -= 1  # index starts from 0\n",
    "            if relabel: pid = pid2label[pid]\n",
    "            dataset.append((img_path, pid, camid))\n",
    "\n",
    "        num_pids = len(pid_container)\n",
    "        num_imgs = len(dataset)\n",
    "        return dataset, num_pids, num_imgs\n",
    "\n",
    "\n",
    "\n",
    "__factory = {\n",
    "    'market': Market1501\n",
    "}\n",
    "\n",
    "\n",
    "def get_names():\n",
    "    return __factory.keys()\n",
    "\n",
    "\n",
    "def init_dataset(name, *args, **kwargs):\n",
    "    if name not in __factory.keys():\n",
    "        raise KeyError(\"Unknown datasets: {}\".format(name))\n",
    "    return __factory[name](*args, **kwargs)\n",
    "\n",
    "\n",
    "dataset=Market1501()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from mxnet.gluon.data.sampler import Sampler\n",
    "\n",
    "\n",
    "class RandomIdentitySampler(Sampler):\n",
    "    def __init__(self, data_source, num_instances=4):\n",
    "        self.data_source = data_source#train_img\n",
    "        self.num_instances = num_instances\n",
    "        self.index_dic = defaultdict(list)\n",
    "        for index, (_, pid, _) in enumerate(data_source):\n",
    "            self.index_dic[pid].append(index)#第几个是当前类别的\n",
    "        self.pids = list(self.index_dic.keys())#类别编号\n",
    "        self.num_identities = len(self.pids)#类别总数\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = np.random.permutation(self.num_identities)\n",
    "        ret = []\n",
    "        for i in indices:\n",
    "            pid = self.pids[i]\n",
    "            t = self.index_dic[pid]\n",
    "            replace = False if len(t) >= self.num_instances else True\n",
    "            t = np.random.choice(t, size=self.num_instances, replace=replace)\n",
    "            ret.extend(t)\n",
    "        return iter(ret)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_identities * self.num_instances#751*4\n",
    "    \n",
    "from mxnet.gluon.data import Dataset\n",
    "\n",
    "class ImageData(Dataset):\n",
    "    def __init__(self, dataset, transform):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img, pid, camid = self.dataset[item]\n",
    "        img = imread(img)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, pid, camid\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def read_image(img_path):\n",
    "        got_img = False\n",
    "        while not got_img:\n",
    "            try:\n",
    "                img = imread(img_path)\n",
    "                got_img = True\n",
    "            except IOError:\n",
    "                print(\"IOError incurred when reading '{}'. Will redo. Don't worry. Just chill.\".format(img_path))\n",
    "                pass\n",
    "        return img\n",
    "\n",
    "from mxnet.gluon.data.vision import transforms as T\n",
    "\n",
    "class TrainTransform(object):\n",
    "    def __init__(self, h, w):\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = Random2DTranslation(self.h, self.w)(x)\n",
    "        x = T.RandomFlipLeftRight()(x)\n",
    "        x = T.RandomColorJitter(brightness=0.4, contrast=0.4,\n",
    "                                              saturation=0.4)(x)\n",
    "        x = T.ToTensor()(x)\n",
    "        x = T.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                        std=(0.229, 0.224, 0.225))(x)\n",
    "#         x = T.Cast(dtype='float16')(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class TestTransform(object):\n",
    "    def __init__(self, h, w):\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "\n",
    "    def __call__(self, x=None):\n",
    "        x = T.Resize((self.w, self.h))(x)\n",
    "        x = T.ToTensor()(x)\n",
    "        x = T.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                        std=(0.229, 0.224, 0.225))(x)\n",
    "#         x = T.Cast(dtype='float16')(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height=224\n",
    "width=224\n",
    "#     height = 256\n",
    "#     width = 128\n",
    "num_instances = 4\n",
    "train_batch=32\n",
    "workers=8\n",
    "test_batch=32\n",
    "\n",
    "galleryloader = DataLoader(\n",
    "        ImageData(dataset.gallery, TestTransform(height, width)),\n",
    "        batch_size=test_batch, num_workers=0,last_batch=\"keep\"\n",
    "    )\n",
    "\n",
    "\n",
    "queryloader = DataLoader(\n",
    "        ImageData(dataset.query, TestTransform(height, width)),\n",
    "        batch_size=test_batch, num_workers=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = gluon.SymbolBlock.imports(symbol_file = 'resnet/jxx_res-symbol.json',ctx=mx.gpu(),\n",
    "                                 param_file= 'resnet/jxx_res-0370.params',\n",
    "                                 input_names=['data']\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx=mx.gpu()\n",
    "for i,inputs in enumerate(galleryloader):\n",
    "    img=inputs[0].as_in_context(ctx)\n",
    "    if i==0:\n",
    "        _,gallery_feature=net(img)\n",
    "        gallery_label = inputs[1]\n",
    "        gallery_cam = inputs[2]\n",
    "    else:     \n",
    "        gallery_label=nd.concat(gallery_label,inputs[1],dim=0)\n",
    "        _,t_feature=net(img)\n",
    "        gallery_feature=nd.concat(gallery_feature,t_feature,dim=0)\n",
    "        gallery_cam=nd.concat(gallery_cam,inputs[2],dim=0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i,inputs in enumerate(galleryloader):\n",
    "#     img=inputs[0].as_in_context(ctx)\n",
    "#     if i==0:\n",
    "#         _,gallery_feature=net(img)\n",
    "#     break\n",
    "# #         gallery_label = inputs[1]\n",
    "# #         gallery_cam = inputs[2]\n",
    "        \n",
    "# # #         gallery_feature=gallery_feature_t.as_in_context(mx.cpu())\n",
    "# # #         gallery_label=gallery_label.as_in_context(mx.cpu())\n",
    "# # #         gallery_feature=gallery_feature.as_in_context(mx.cpu())\n",
    "# #     else:     \n",
    "# #         gallery_label=nd.concat(gallery_label,inputs[1],dim=0)\n",
    "# #         _,t_feature=net(img)\n",
    "# # #         t_feature=t_feature.as_in_context(mx.cpu())\n",
    "        \n",
    "# #         gallery_feature=nd.concat(gallery_feature,t_feature,dim=0)\n",
    "# #         gallery_cam=nd.concat(gallery_cam,inputs[2],dim=0)\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = {'gallery_f':gallery_feature.asnumpy(),\n",
    "          'gallery_label':gallery_label.asnumpy(),\n",
    "          'gallery_cam':gallery_cam.asnumpy(),\n",
    "\n",
    "         }\n",
    "# result={\"label\":gallery_label.asnumpy()}\n",
    "sio.savemat('result_res_gallery.mat',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gallery_feature[1].asnumpy()[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,inputs in enumerate(queryloader):\n",
    "    img=inputs[0].as_in_context(ctx)\n",
    "    if i==0:\n",
    "        _,query_feature=net(img)\n",
    "        query_label = inputs[1]\n",
    "        query_cam = inputs[2]\n",
    "    else:     \n",
    "        query_label=nd.concat(query_label,inputs[1],dim=0)\n",
    "        _,t_feature=net(img)\n",
    "        query_feature=nd.concat(query_feature,t_feature,dim=0)\n",
    "        query_cam=nd.concat(query_cam,inputs[2],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,inputs in enumerate(galleryloader):\n",
    "    img=inputs[0].as_in_context(ctx)\n",
    "    if i==0:\n",
    "        _,gallery_feature=net(img)\n",
    "        gallery_label = inputs[1]\n",
    "        gallery_cam = inputs[2]\n",
    "    else:     \n",
    "        gallery_label=nd.concat(gallery_label,inputs[1],dim=0)\n",
    "        _,t_feature=net(img)\n",
    "        gallery_feature=nd.concat(gallery_feature,t_feature,dim=0)\n",
    "        gallery_cam=nd.concat(gallery_cam,inputs[2],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = {'gallery_f':gallery_feature.asnumpy(),\n",
    "          'gallery_label':gallery_label.asnumpy(),\n",
    "          'gallery_cam':gallery_cam.asnumpy(),\n",
    "          'query_f':query_feature.asnumpy(),\n",
    "          'query_label':query_label.asnumpy(),\n",
    "          'query_cam':query_cam.asnumpy()\n",
    "         }\n",
    "# result={\"label\":gallery_label.asnumpy()}\n",
    "sio.savemat('result_res.mat',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
